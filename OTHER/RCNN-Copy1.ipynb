{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK FOR COMPETITION: NOTE THAT KERAS IS USED AND IS THUS NOT A VALID ATTEMPT FOR THE COMPETETION\n",
    "Since we have expererience with DL it seemed redundant to do it all from scatch and instead we used the time to get more familiar with DL libraries to get a better practical understanding of developing neural networks. Thus the results in this notebook are not eligble for competetion however they show the strength of leveraging a strong framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load required packages\n",
    "import numpy as np\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "num_classes = 10\n",
    "opt = \"adam\"\n",
    "loss_f = 'categorical_crossentropy'\n",
    "batch_size = 64\n",
    "nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Normalize data and turn to categorical\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n62u4GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc49fc88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Augment the input data to get more training data.\n",
    "#Section is inspired by: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 10, \n",
    "                             width_shift_range = 0.1,\n",
    "                             height_shift_range = 0.1,\n",
    "                             zoom_range = 0.1)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#Show result\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break\n",
    "    \n",
    "train_generator = datagen.flow(X_train, y_train, batch_size = batch_size)\n",
    "\n",
    "#Define validation generator\n",
    "test_gen = ImageDataGenerator()\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 28, 28, 64)   640         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 28, 28, 28)   1820        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 28, 28, 28)   112         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_41 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_31 (Merge)                (None, 28, 28, 28)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 28, 28, 28)   112         merge_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_42 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_32 (Merge)                (None, 28, 28, 28)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 28, 28, 28)   112         merge_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_43 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_33 (Merge)                (None, 28, 28, 28)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 28, 28, 28)   112         merge_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_44 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 28)   0           p_re_lu_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 28, 28, 28)   812         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 28, 28, 28)   112         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_45 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_34 (Merge)                (None, 28, 28, 28)   0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 28, 28, 28)   112         merge_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_46 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_35 (Merge)                (None, 28, 28, 28)   0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 28, 28, 28)   112         merge_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_47 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_36 (Merge)                (None, 28, 28, 28)   0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 28, 28, 28)   112         merge_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_48 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 28)   0           p_re_lu_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 14, 14, 28)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 28)   812         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 28)   112         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_49 (PReLU)              (None, 14, 14, 28)   5488        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 28)   7084        p_re_lu_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_37 (Merge)                (None, 14, 14, 28)   0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 28)   112         merge_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_50 (PReLU)              (None, 14, 14, 28)   5488        batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 28)   7084        p_re_lu_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_38 (Merge)                (None, 14, 14, 28)   0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 28)   112         merge_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_51 (PReLU)              (None, 14, 14, 28)   5488        batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 28)   7084        p_re_lu_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_39 (Merge)                (None, 14, 14, 28)   0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 28)   112         merge_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_52 (PReLU)              (None, 14, 14, 28)   5488        batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 14, 14, 28)   0           p_re_lu_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5488)         0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           54890       flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 321,642\n",
      "Trainable params: 320,970\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Define model.\n",
    "#We use two convolutional blocks, which both contains two convolutinal\n",
    "#with maxpooling at the end. Finally put result into a dense layer.\n",
    "from Keras_RCNN import BuildRCNN\n",
    "\n",
    "model = BuildRCNN(1, 28, 28, nbClasses=num_classes, nbRCL=3, nbFilters=64, filtersize= 3)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=loss_f,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9767Epoch 00001: val_acc improved from -inf to 0.98880, saving model to weights.best.hdf5\n",
      "938/937 [==============================] - 47s 50ms/step - loss: 0.0779 - acc: 0.9767 - val_loss: 0.0353 - val_acc: 0.9888\n",
      "Epoch 2/10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9806Epoch 00002: val_acc improved from 0.98880 to 0.99070, saving model to weights.best.hdf5\n",
      "938/937 [==============================] - 47s 50ms/step - loss: 0.0650 - acc: 0.9806 - val_loss: 0.0273 - val_acc: 0.9907\n",
      "Epoch 3/10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9824Epoch 00003: val_acc did not improve\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0579 - acc: 0.9824 - val_loss: 0.0377 - val_acc: 0.9873\n",
      "Epoch 4/10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9841- ETA: 1s - loss: 0.0Epoch 00004: val_acc improved from 0.99070 to 0.99130, saving model to weights.best.hdf5\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0521 - acc: 0.9842 - val_loss: 0.0261 - val_acc: 0.9913\n",
      "Epoch 5/10\n",
      "937/937 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9844Epoch 00005: val_acc did not improve\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0497 - acc: 0.9844 - val_loss: 0.0311 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "937/937 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9856Epoch 00006: val_acc did not improve\n",
      "938/937 [==============================] - 48s 52ms/step - loss: 0.0457 - acc: 0.9856 - val_loss: 0.0327 - val_acc: 0.9892\n",
      "Epoch 7/10\n",
      "937/937 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9862Epoch 00007: val_acc improved from 0.99130 to 0.99300, saving model to weights.best.hdf5\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0433 - acc: 0.9862 - val_loss: 0.0196 - val_acc: 0.9930\n",
      "Epoch 8/10\n",
      "937/937 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9873Epoch 00008: val_acc improved from 0.99300 to 0.99330, saving model to weights.best.hdf5\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0408 - acc: 0.9873 - val_loss: 0.0222 - val_acc: 0.9933\n",
      "Epoch 9/10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9883Epoch 00009: val_acc did not improve\n",
      "938/937 [==============================] - 49s 52ms/step - loss: 0.0381 - acc: 0.9883 - val_loss: 0.0463 - val_acc: 0.9849\n",
      "Epoch 10/10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9878Epoch 00010: val_acc did not improve\n",
      "938/937 [==============================] - 48s 51ms/step - loss: 0.0394 - acc: 0.9878 - val_loss: 0.0206 - val_acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit(x=X_train, y=y_train, batch_size = batch_size, \\n          epochs=nb_epochs, validation_data= (X_test, y_test))\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Fit Model\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = len(X_train) / batch_size,\n",
    "                    epochs = nb_epochs,\n",
    "                    validation_data = test_generator,\n",
    "                    validation_steps = len(y_test)/ batch_size,\n",
    "                    callbacks = callbacks_list)\n",
    "\n",
    "\"\"\"\n",
    "model.fit(x=X_train, y=y_train, batch_size = batch_size, \n",
    "          epochs=nb_epochs, validation_data= (X_test, y_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of model\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "#Compile the model\n",
    "model.compile(loss=loss_f,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
