{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK FOR COMPETITION: NOTE THAT KERAS IS USED AND IS THUS NOT A VALID ATTEMPT FOR THE COMPETETION\n",
    "Since we have expererience with DL it seemed redundant to do it all from scatch and instead we used the time to get more familiar with DL libraries to get a better practical understanding of developing neural networks. Thus the results in this notebook are not eligble for competetion however they show the strength of leveraging a strong framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load required packages\n",
    "import numpy as np\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "num_classes = 10\n",
    "opt = \"adam\"\n",
    "loss_f = 'categorical_crossentropy'\n",
    "batch_size = 64\n",
    "nb_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Normalize data and turn to categorical\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c70458f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Augment the input data to get more training data.\n",
    "#Section is inspired by: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 20, \n",
    "                             width_shift_range = 0.1,\n",
    "                             height_shift_range = 0.1,\n",
    "                             zoom_range=0.2)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#Show result\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break\n",
    "    \n",
    "train_generator = datagen.flow(X_train, y_train, batch_size = batch_size)\n",
    "\n",
    "#Define validation generator\n",
    "test_gen = ImageDataGenerator()\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 727,530\n",
      "Trainable params: 725,610\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Define model.\n",
    "#We use two convolutional blocks, which both contains two convolutinal\n",
    "#with maxpooling at the end. Finally put result into a dense layer.\n",
    "model = Sequential()\n",
    "\n",
    "#First conv layer\n",
    "model.add(Convolution2D(32, (3, 3), input_shape = (28,28, 1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(32, (3,3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second conv layer\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(64, (3,3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "#Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=loss_f,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.3302 - acc: 0.8970Epoch 00001: val_acc improved from -inf to 0.79960, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 14s 29ms/step - loss: 0.3293 - acc: 0.8973 - val_loss: 0.6106 - val_acc: 0.7996\n",
      "Epoch 2/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9595Epoch 00002: val_acc improved from 0.79960 to 0.98670, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 11s 23ms/step - loss: 0.1292 - acc: 0.9596 - val_loss: 0.0389 - val_acc: 0.9867\n",
      "Epoch 3/15\n",
      "468/468 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9680Epoch 00003: val_acc did not improve\n",
      "469/468 [==============================] - 11s 24ms/step - loss: 0.1019 - acc: 0.9681 - val_loss: 0.0500 - val_acc: 0.9832\n",
      "Epoch 4/15\n",
      "468/468 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9713- ETA: 1s - loss: 0.Epoch 00004: val_acc improved from 0.98670 to 0.99230, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 12s 27ms/step - loss: 0.0899 - acc: 0.9713 - val_loss: 0.0262 - val_acc: 0.9923\n",
      "Epoch 5/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9739Epoch 00005: val_acc did not improve\n",
      "469/468 [==============================] - 12s 26ms/step - loss: 0.0831 - acc: 0.9739 - val_loss: 0.0520 - val_acc: 0.9825\n",
      "Epoch 6/15\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9744Epoch 00006: val_acc did not improve\n",
      "469/468 [==============================] - 13s 28ms/step - loss: 0.0829 - acc: 0.9744 - val_loss: 0.0338 - val_acc: 0.9894\n",
      "Epoch 7/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9782Epoch 00007: val_acc did not improve\n",
      "469/468 [==============================] - 12s 26ms/step - loss: 0.0736 - acc: 0.9782 - val_loss: 0.0330 - val_acc: 0.9891\n",
      "Epoch 8/15\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9777Epoch 00008: val_acc improved from 0.99230 to 0.99280, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 12s 25ms/step - loss: 0.0725 - acc: 0.9777 - val_loss: 0.0223 - val_acc: 0.9928\n",
      "Epoch 9/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9804Epoch 00009: val_acc did not improve\n",
      "469/468 [==============================] - 11s 24ms/step - loss: 0.0664 - acc: 0.9804 - val_loss: 0.0367 - val_acc: 0.9888\n",
      "Epoch 10/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9809Epoch 00010: val_acc improved from 0.99280 to 0.99330, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 12s 25ms/step - loss: 0.0642 - acc: 0.9810 - val_loss: 0.0197 - val_acc: 0.9933\n",
      "Epoch 11/15\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9811Epoch 00011: val_acc did not improve\n",
      "469/468 [==============================] - 11s 24ms/step - loss: 0.0625 - acc: 0.9812 - val_loss: 0.0251 - val_acc: 0.9914\n",
      "Epoch 12/15\n",
      "468/468 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9808- ETA: 1s - Epoch 00012: val_acc did not improve\n",
      "469/468 [==============================] - 11s 24ms/step - loss: 0.0610 - acc: 0.9808 - val_loss: 0.0225 - val_acc: 0.9927\n",
      "Epoch 13/15\n",
      "468/468 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9819Epoch 00013: val_acc improved from 0.99330 to 0.99380, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 11s 25ms/step - loss: 0.0584 - acc: 0.9820 - val_loss: 0.0181 - val_acc: 0.9938\n",
      "Epoch 14/15\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9811Epoch 00014: val_acc improved from 0.99380 to 0.99410, saving model to weights_CNN.best.hdf5\n",
      "469/468 [==============================] - 12s 25ms/step - loss: 0.0603 - acc: 0.9811 - val_loss: 0.0200 - val_acc: 0.9941\n",
      "Epoch 15/15\n",
      "468/468 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9836Epoch 00015: val_acc did not improve\n",
      "469/468 [==============================] - 11s 24ms/step - loss: 0.0516 - acc: 0.9836 - val_loss: 0.0241 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cb9dc2ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model under training\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights_CNN.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "#Fit the model\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = len(X_train) / (2*batch_size),\n",
    "                    epochs = nb_epochs,\n",
    "                    validation_data = test_generator,\n",
    "                    validation_steps = len(y_test)/ batch_size,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of model\n",
    "model.load_weights(\"weights_CNN.best.hdf5\")\n",
    "#Compile the model\n",
    "model.compile(loss=loss_f,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
