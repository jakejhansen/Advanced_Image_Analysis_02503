{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK FOR COMPETITION: NOTE THAT KERAS IS USED AND IS THUS NOT A VALID ATTEMPT FOR THE COMPETETION\n",
    "Since we have expererience with DL it seemed redundant to do it all from scatch and instead we used the time to get more familiar with DL libraries to get a better practical understanding of developing neural networks. Thus the results in this notebook are not eligble for competetion however they show the strength of leveraging a strong framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required packages\n",
    "import numpy as np\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "num_classes = 10\n",
    "opt = \"adam\"\n",
    "loss_f = 'categorical_crossentropy'\n",
    "batch_size = 64\n",
    "nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Normalize data and turn to categorical\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3c3bb3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Augment the input data to get more training data.\n",
    "#Section is inspired by: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 20, \n",
    "                             width_shift_range = 0.1,\n",
    "                             height_shift_range = 0.1,\n",
    "                             zoom_range=0.2)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#Show result\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break\n",
    "    \n",
    "train_generator = datagen.flow(X_train, y_train, batch_size = batch_size)\n",
    "\n",
    "#Define validation generator\n",
    "test_gen = ImageDataGenerator()\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 28)   924         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 28)   112         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 28, 28, 28)   21952       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_7 (Merge)                 (None, 28, 28, 28)   0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 28)   112         merge_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_8 (Merge)                 (None, 28, 28, 28)   0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 28)   112         merge_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_9 (Merge)                 (None, 28, 28, 28)   0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 28)   112         merge_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 28)   0           p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 28)   812         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 28)   112         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_10 (Merge)                (None, 28, 28, 28)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 28)   112         merge_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_11 (Merge)                (None, 28, 28, 28)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 28)   112         merge_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 28)   7084        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_12 (Merge)                (None, 28, 28, 28)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 28)   112         merge_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 28, 28, 28)   21952       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 28)   0           p_re_lu_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 28)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5488)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           54890       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 275,962\n",
      "Trainable params: 275,514\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Define model.\n",
    "#We use two convolutional blocks, which both contains two convolutinal\n",
    "#with maxpooling at the end. Finally put result into a dense layer.\n",
    "from Keras_RCNN import BuildRCNN\n",
    "\n",
    "model = BuildRCNN(1, 28, 28, nbClasses=num_classes, nbRCL=2, nbFilters=32, filtersize= 3)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=loss_f,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/937 [==============================] - 38s 41ms/step - loss: 0.3769 - acc: 0.8847 - val_loss: 0.1383 - val_acc: 0.9617\n",
      "Epoch 2/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.1434 - acc: 0.9564 - val_loss: 0.0906 - val_acc: 0.9717\n",
      "Epoch 3/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.1125 - acc: 0.9668 - val_loss: 0.0417 - val_acc: 0.9863\n",
      "Epoch 4/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.0930 - acc: 0.9722 - val_loss: 0.0574 - val_acc: 0.9831\n",
      "Epoch 5/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.0856 - acc: 0.9738 - val_loss: 0.0328 - val_acc: 0.9897\n",
      "Epoch 6/10\n",
      "938/937 [==============================] - 36s 39ms/step - loss: 0.0790 - acc: 0.9754 - val_loss: 0.0421 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.0717 - acc: 0.9787 - val_loss: 0.0262 - val_acc: 0.9919\n",
      "Epoch 8/10\n",
      "938/937 [==============================] - 36s 39ms/step - loss: 0.0693 - acc: 0.9784 - val_loss: 0.0247 - val_acc: 0.9909\n",
      "Epoch 9/10\n",
      "938/937 [==============================] - 36s 38ms/step - loss: 0.0664 - acc: 0.9796 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "938/937 [==============================] - 36s 39ms/step - loss: 0.0626 - acc: 0.9811 - val_loss: 0.0337 - val_acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit(x=X_train, y=y_train, batch_size = batch_size, \\n          epochs=nb_epochs, validation_data= (X_test, y_test))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = len(X_train) / batch_size,\n",
    "                    epochs = nb_epochs,\n",
    "                    validation_data = test_generator,\n",
    "                    validation_steps = len(y_test)/ batch_size)\n",
    "\n",
    "\"\"\"\n",
    "model.fit(x=X_train, y=y_train, batch_size = batch_size, \n",
    "          epochs=nb_epochs, validation_data= (X_test, y_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9895\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
