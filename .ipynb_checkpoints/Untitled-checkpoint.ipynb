{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n",
      "                             [--seed S] [--log-interval N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-b7be7d33-cc37-4c3f-9900-23eae6cd61c6.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import sklearn.datasets\n",
    "    \n",
    "from torchsample.modules import ModuleTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/Da+iSMAAAAFSURBVD/BCmqVs+yezQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f874bac8f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load data\n",
    "X, y = sklearn.datasets.make_blobs(n_samples=100, n_features=2, centers=[[-1,-1], [1, 1]], cluster_std=0.5)\n",
    "\n",
    "y = y\n",
    "\n",
    "colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "colors = np.hstack([colors] * 20)\n",
    "plt.scatter(X[:, 0], X[:, 1], color=colors[y].tolist())\n",
    "plt.show()\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 0/4 [00:00<?, ? batches/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "Epoch 1/200: : 5 batches [00:00, 272.06 batches/s, loss=[]]                   \n",
      "Epoch 2/200: : 5 batches [00:00, 138.79 batches/s, loss=[]]                   \n",
      "Epoch 3/200: : 5 batches [00:00, 234.11 batches/s, loss=[]]                   \n",
      "Epoch 4/200: : 5 batches [00:00, 407.35 batches/s, loss=[]]                   \n",
      "Epoch 5/200: : 5 batches [00:00, 405.68 batches/s, loss=[]]                   \n",
      "Epoch 6/200: : 5 batches [00:00, 60.85 batches/s, loss=[]]                   \n",
      "Epoch 7/200: : 5 batches [00:00, 189.41 batches/s, loss=[]]                   \n",
      "Epoch 8/200: : 5 batches [00:00, 131.71 batches/s, loss=[]]                   \n",
      "Epoch 9/200: : 5 batches [00:00, 78.32 batches/s, loss=[]]                   \n",
      "Epoch 10/200: : 5 batches [00:00, 139.75 batches/s, loss=[]]                   \n",
      "Epoch 11/200: : 5 batches [00:00, 810.18 batches/s, loss=[]]                   \n",
      "Epoch 12/200: : 5 batches [00:00, 73.86 batches/s, loss=[]]                   \n",
      "Epoch 13/200: : 5 batches [00:00, 82.43 batches/s, loss=[]]                   \n",
      "Epoch 14/200: : 5 batches [00:00, 69.54 batches/s, loss=[]]                   \n",
      "Epoch 15/200: : 5 batches [00:00, 193.59 batches/s, loss=[]]                   \n",
      "Epoch 16/200: : 5 batches [00:00, 259.98 batches/s, loss=[]]                   \n",
      "Epoch 17/200: : 5 batches [00:00, 55.00 batches/s, loss=[]]                   \n",
      "Epoch 18/200: : 5 batches [00:00, 245.11 batches/s, loss=[]]                   \n",
      "Epoch 19/200: : 5 batches [00:00, 309.72 batches/s, loss=[]]                   \n",
      "Epoch 20/200: : 5 batches [00:00, 57.99 batches/s, loss=[]]                   \n",
      "Epoch 21/200: : 5 batches [00:00, 134.69 batches/s, loss=[]]                   \n",
      "Epoch 22/200: : 5 batches [00:00, 58.36 batches/s, loss=[]]                   \n",
      "Epoch 23/200: : 5 batches [00:00, 135.36 batches/s, loss=[]]                   \n",
      "Epoch 24/200: : 5 batches [00:00, 52.96 batches/s, loss=[]]                   \n",
      "Epoch 25/200: : 5 batches [00:00, 154.92 batches/s, loss=[]]                   \n",
      "Epoch 26/200: : 5 batches [00:00, 246.72 batches/s, loss=[]]                   \n",
      "Epoch 27/200: : 5 batches [00:00, 85.98 batches/s, loss=[]]                   \n",
      "Epoch 28/200: : 5 batches [00:00, 53.81 batches/s, loss=[]]                   \n",
      "Epoch 29/200: : 5 batches [00:00, 68.43 batches/s, loss=[]]                   \n",
      "Epoch 30/200: : 5 batches [00:00, 139.12 batches/s, loss=[]]                   \n",
      "Epoch 31/200: : 5 batches [00:00, 55.61 batches/s, loss=[]]                   \n",
      "Epoch 32/200: : 5 batches [00:00, 97.40 batches/s, loss=[]]                   \n",
      "Epoch 33/200: : 5 batches [00:00, 68.01 batches/s, loss=[]]                   \n",
      "Epoch 34/200: : 5 batches [00:00, 56.75 batches/s, loss=[]]                   \n",
      "Epoch 35/200: : 5 batches [00:00, 160.00 batches/s, loss=[]]                   \n",
      "Epoch 36/200: : 5 batches [00:00, 306.87 batches/s, loss=[]]                   \n",
      "Epoch 37/200: : 5 batches [00:00, 269.92 batches/s, loss=[]]                   \n",
      "Epoch 38/200: : 5 batches [00:00, 92.26 batches/s, loss=[]]                    \n",
      "Epoch 39/200: : 5 batches [00:00, 50.85 batches/s, loss=[]]                   \n",
      "Epoch 40/200: : 5 batches [00:00, 52.06 batches/s, loss=[]]                   \n",
      "Epoch 41/200: : 5 batches [00:00, 57.12 batches/s, loss=[]]                   \n",
      "Epoch 42/200: : 5 batches [00:00, 58.83 batches/s, loss=[]]                   \n",
      "Epoch 43/200: : 5 batches [00:00, 54.94 batches/s, loss=[]]                   \n",
      "Epoch 44/200: : 5 batches [00:00, 126.07 batches/s, loss=[]]                   \n",
      "Epoch 45/200: : 5 batches [00:00, 69.78 batches/s, loss=[]]                   \n",
      "Epoch 46/200: : 5 batches [00:00, 109.37 batches/s, loss=[]]                  \n",
      "Epoch 47/200: : 5 batches [00:00, 59.38 batches/s, loss=[]]                   \n",
      "Epoch 48/200: : 5 batches [00:00, 227.92 batches/s, loss=[]]                   \n",
      "Epoch 49/200: : 5 batches [00:00, 83.14 batches/s, loss=[]]                   \n",
      "Epoch 50/200: : 5 batches [00:00, 41.36 batches/s, loss=[]]                   \n",
      "Epoch 51/200: : 5 batches [00:00, 100.59 batches/s, loss=[]]                  \n",
      "Epoch 52/200: : 5 batches [00:00, 58.52 batches/s, loss=[]]                   \n",
      "Epoch 53/200: : 5 batches [00:00, 143.78 batches/s, loss=[]]                   \n",
      "Epoch 54/200: : 5 batches [00:00, 217.76 batches/s, loss=[]]                   \n",
      "Epoch 55/200: : 5 batches [00:00, 52.81 batches/s, loss=[]]                   \n",
      "Epoch 56/200: : 5 batches [00:00, 44.58 batches/s, loss=[]]                   \n",
      "Epoch 57/200: : 5 batches [00:00, 188.19 batches/s, loss=[]]                   \n",
      "Epoch 58/200: : 5 batches [00:00, 76.74 batches/s, loss=[]]                   \n",
      "Epoch 59/200: : 5 batches [00:00, 89.16 batches/s, loss=[]]                   \n",
      "Epoch 60/200: : 5 batches [00:00, 175.60 batches/s, loss=[]]                   \n",
      "Epoch 61/200: : 5 batches [00:00, 46.19 batches/s, loss=[]]                   \n",
      "Epoch 62/200: : 5 batches [00:00, 70.95 batches/s, loss=[]]                   \n",
      "Epoch 63/200: : 5 batches [00:00, 73.70 batches/s, loss=[]]                   \n",
      "Epoch 64/200: : 5 batches [00:00, 48.28 batches/s, loss=[]]                   \n",
      "Epoch 65/200: : 5 batches [00:00, 42.92 batches/s, loss=[]]                   \n",
      "Epoch 66/200: : 5 batches [00:00, 46.78 batches/s, loss=[]]                   \n",
      "Epoch 67/200: : 5 batches [00:00, 64.00 batches/s, loss=[]]                   \n",
      "Epoch 68/200: : 5 batches [00:00, 180.22 batches/s, loss=[]]                   \n",
      "Epoch 69/200: : 5 batches [00:00, 51.51 batches/s, loss=[]]                   \n",
      "Epoch 70/200: : 5 batches [00:00, 78.17 batches/s, loss=[]]                    \n",
      "Epoch 71/200: : 5 batches [00:00, 187.10 batches/s, loss=[]]                   \n",
      "Epoch 72/200: : 5 batches [00:00, 83.49 batches/s, loss=[]]                   \n",
      "Epoch 73/200: : 5 batches [00:00, 42.62 batches/s, loss=[]]                   \n",
      "Epoch 74/200: : 5 batches [00:00, 112.46 batches/s, loss=[]]                   \n",
      "Epoch 75/200: : 5 batches [00:00, 67.37 batches/s, loss=[]]                   \n",
      "Epoch 76/200: : 5 batches [00:00, 57.37 batches/s, loss=[]]                    \n",
      "Epoch 77/200: : 5 batches [00:00, 117.11 batches/s, loss=[]]                   \n",
      "Epoch 78/200: : 5 batches [00:00, 46.77 batches/s, loss=[]]                   \n",
      "Epoch 79/200: : 5 batches [00:00, 46.30 batches/s, loss=[]]                   \n",
      "Epoch 80/200: : 5 batches [00:00, 96.67 batches/s, loss=[]]                   \n",
      "Epoch 81/200: : 5 batches [00:00, 97.38 batches/s, loss=[]]                    \n",
      "Epoch 82/200: : 5 batches [00:00, 76.86 batches/s, loss=[]]                   \n",
      "Epoch 83/200: : 5 batches [00:00, 50.42 batches/s, loss=[]]                   \n",
      "Epoch 84/200: : 5 batches [00:00, 50.96 batches/s, loss=[]]                   \n",
      "Epoch 85/200: : 5 batches [00:00, 48.44 batches/s, loss=[]]                   \n",
      "Epoch 86/200: : 5 batches [00:00, 48.62 batches/s, loss=[]]                   \n",
      "Epoch 87/200: : 5 batches [00:00, 49.13 batches/s, loss=[]]                   \n",
      "Epoch 88/200: : 5 batches [00:00, 189.52 batches/s, loss=[]]                   \n",
      "Epoch 89/200: : 5 batches [00:00, 87.17 batches/s, loss=[]]                   \n",
      "Epoch 90/200: : 5 batches [00:00, 46.48 batches/s, loss=[]]                   \n",
      "Epoch 91/200: : 5 batches [00:00, 117.09 batches/s, loss=[]]                   \n",
      "Epoch 92/200: : 5 batches [00:00, 64.48 batches/s, loss=[]]                   \n",
      "Epoch 93/200: : 5 batches [00:00, 105.01 batches/s, loss=[]]                  \n",
      "Epoch 94/200: : 5 batches [00:00, 233.14 batches/s, loss=[]]                   \n",
      "Epoch 95/200: : 5 batches [00:00, 62.18 batches/s, loss=[]]                   \n",
      "Epoch 96/200: : 5 batches [00:00, 48.11 batches/s, loss=[]]                   \n",
      "Epoch 97/200: : 5 batches [00:00, 113.81 batches/s, loss=[]]                   \n",
      "Epoch 98/200: : 5 batches [00:00, 115.84 batches/s, loss=[]]                   \n",
      "Epoch 99/200: : 5 batches [00:00, 49.79 batches/s, loss=[]]                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/200: : 5 batches [00:00, 92.96 batches/s, loss=[]]                    \n",
      "Epoch 101/200: : 5 batches [00:00, 48.14 batches/s, loss=[]]                   \n",
      "Epoch 102/200: : 5 batches [00:00, 110.11 batches/s, loss=[]]                   \n",
      "Epoch 103/200: : 5 batches [00:00, 136.04 batches/s, loss=[]]                   \n",
      "Epoch 104/200: : 5 batches [00:00, 407.60 batches/s, loss=[]]                   \n",
      "Epoch 105/200: : 5 batches [00:00, 809.12 batches/s, loss=[]]                   \n",
      "Epoch 106/200: : 5 batches [00:00, 312.47 batches/s, loss=[]]                   \n",
      "Epoch 107/200: : 5 batches [00:00, 213.19 batches/s, loss=[]]                   \n",
      "Epoch 108/200: : 5 batches [00:00, 390.98 batches/s, loss=[]]                   \n",
      "Epoch 109/200: : 5 batches [00:00, 188.21 batches/s, loss=[]]                   \n",
      "Epoch 110/200: : 5 batches [00:00, 283.31 batches/s, loss=[]]                   \n",
      "Epoch 111/200: : 5 batches [00:00, 248.44 batches/s, loss=[]]                   \n",
      "Epoch 112/200: : 5 batches [00:00, 262.48 batches/s, loss=[]]                   \n",
      "Epoch 113/200: : 5 batches [00:00, 593.71 batches/s, loss=[]]                   \n",
      "Epoch 114/200: : 5 batches [00:00, 392.68 batches/s, loss=[]]                   \n",
      "Epoch 115/200: : 5 batches [00:00, 335.20 batches/s, loss=[]]                   \n",
      "Epoch 116/200: : 5 batches [00:00, 259.30 batches/s, loss=[]]                   \n",
      "Epoch 117/200: : 5 batches [00:00, 295.97 batches/s, loss=[]]                   \n",
      "Epoch 118/200: : 5 batches [00:00, 112.34 batches/s, loss=[]]                  \n",
      "Epoch 119/200: : 5 batches [00:00, 400.27 batches/s, loss=[]]                   \n",
      "Epoch 120/200: : 5 batches [00:00, 208.58 batches/s, loss=[]]                   \n",
      "Epoch 121/200: : 5 batches [00:00, 138.39 batches/s, loss=[]]                   \n",
      "Epoch 122/200: : 5 batches [00:00, 650.12 batches/s, loss=[]]                   \n",
      "Epoch 123/200: : 5 batches [00:00, 303.27 batches/s, loss=[]]                   \n",
      "Epoch 124/200: : 5 batches [00:00, 220.10 batches/s, loss=[]]                   \n",
      "Epoch 125/200: : 5 batches [00:00, 393.34 batches/s, loss=[]]                   \n",
      "Epoch 126/200: : 5 batches [00:00, 327.37 batches/s, loss=[]]                   \n",
      "Epoch 127/200: : 5 batches [00:00, 238.91 batches/s, loss=[]]                   \n",
      "Epoch 128/200: : 5 batches [00:00, 363.92 batches/s, loss=[]]                   \n",
      "Epoch 129/200: : 5 batches [00:00, 186.99 batches/s, loss=[]]                   \n",
      "Epoch 130/200: : 5 batches [00:00, 268.83 batches/s, loss=[]]                   \n",
      "Epoch 131/200: : 5 batches [00:00, 223.59 batches/s, loss=[]]                   \n",
      "Epoch 132/200: : 5 batches [00:00, 377.89 batches/s, loss=[]]                   \n",
      "Epoch 133/200: : 5 batches [00:00, 132.20 batches/s, loss=[]]                   \n",
      "Epoch 134/200: : 5 batches [00:00, 527.13 batches/s, loss=[]]                   \n",
      "Epoch 135/200: : 5 batches [00:00, 238.13 batches/s, loss=[]]                   \n",
      "Epoch 136/200: : 5 batches [00:00, 236.94 batches/s, loss=[]]                   \n",
      "Epoch 137/200: : 5 batches [00:00, 385.87 batches/s, loss=[]]                   \n",
      "Epoch 138/200: : 5 batches [00:00, 177.30 batches/s, loss=[]]                   \n",
      "Epoch 139/200: : 5 batches [00:00, 138.04 batches/s, loss=[]]                   \n",
      "Epoch 140/200: : 5 batches [00:00, 83.11 batches/s, loss=[]]                   \n",
      "Epoch 141/200: : 5 batches [00:00, 230.66 batches/s, loss=[]]                   \n",
      "Epoch 142/200: : 5 batches [00:00, 158.81 batches/s, loss=[]]                   \n",
      "Epoch 143/200: : 5 batches [00:00, 233.99 batches/s, loss=[]]                   \n",
      "Epoch 144/200: : 5 batches [00:00, 240.70 batches/s, loss=[]]                   \n",
      "Epoch 145/200: : 5 batches [00:00, 222.00 batches/s, loss=[]]                   \n",
      "Epoch 146/200: : 5 batches [00:00, 365.66 batches/s, loss=[]]                   \n",
      "Epoch 147/200: : 5 batches [00:00, 380.38 batches/s, loss=[]]                   \n",
      "Epoch 148/200: : 5 batches [00:00, 180.70 batches/s, loss=[]]                   \n",
      "Epoch 149/200: : 5 batches [00:00, 112.09 batches/s, loss=[]]                  \n",
      "Epoch 150/200: : 5 batches [00:00, 112.13 batches/s, loss=[]]                   \n",
      "Epoch 151/200: : 5 batches [00:00, 73.15 batches/s, loss=[]]                   \n",
      "Epoch 152/200: : 5 batches [00:00, 112.64 batches/s, loss=[]]                  \n",
      "Epoch 153/200: : 5 batches [00:00, 174.64 batches/s, loss=[]]                   \n",
      "Epoch 154/200: : 5 batches [00:00, 87.86 batches/s, loss=[]]                   \n",
      "Epoch 155/200: : 5 batches [00:00, 109.04 batches/s, loss=[]]                   \n",
      "Epoch 156/200: : 5 batches [00:00, 86.40 batches/s, loss=[]]                   \n",
      "Epoch 157/200: : 5 batches [00:00, 57.47 batches/s, loss=[]]                   \n",
      "Epoch 158/200: : 5 batches [00:00, 152.04 batches/s, loss=[]]                   \n",
      "Epoch 159/200: : 5 batches [00:00, 115.08 batches/s, loss=[]]                   \n",
      "Epoch 160/200: : 5 batches [00:00, 115.52 batches/s, loss=[]]                   \n",
      "Epoch 161/200: : 5 batches [00:00, 211.26 batches/s, loss=[]]                   \n",
      "Epoch 162/200: : 5 batches [00:00, 173.90 batches/s, loss=[]]                   \n",
      "Epoch 163/200: : 5 batches [00:00, 254.98 batches/s, loss=[]]                   \n",
      "Epoch 164/200: : 5 batches [00:00, 109.76 batches/s, loss=[]]                  \n",
      "Epoch 165/200: : 5 batches [00:00, 100.89 batches/s, loss=[]]                  \n",
      "Epoch 166/200: : 5 batches [00:00, 62.39 batches/s, loss=[]]                   \n",
      "Epoch 167/200: : 5 batches [00:00, 272.23 batches/s, loss=[]]                   \n",
      "Epoch 168/200: : 5 batches [00:00, 333.24 batches/s, loss=[]]                   \n",
      "Epoch 169/200: : 5 batches [00:00, 249.02 batches/s, loss=[]]                   \n",
      "Epoch 170/200: : 5 batches [00:00, 88.00 batches/s, loss=[]]                   \n",
      "Epoch 171/200: : 5 batches [00:00, 236.11 batches/s, loss=[]]                   \n",
      "Epoch 172/200: : 5 batches [00:00, 94.22 batches/s, loss=[]]                   \n",
      "Epoch 173/200: : 5 batches [00:00, 117.05 batches/s, loss=[]]                   \n",
      "Epoch 174/200: : 5 batches [00:00, 305.24 batches/s, loss=[]]                   \n",
      "Epoch 175/200: : 5 batches [00:00, 217.66 batches/s, loss=[]]                   \n",
      "Epoch 176/200: : 5 batches [00:00, 112.36 batches/s, loss=[]]                  \n",
      "Epoch 177/200: : 5 batches [00:00, 63.79 batches/s, loss=[]]                   \n",
      "Epoch 178/200: : 5 batches [00:00, 76.77 batches/s, loss=[]]                   \n",
      "Epoch 179/200: : 5 batches [00:00, 275.53 batches/s, loss=[]]                   \n",
      "Epoch 180/200: : 5 batches [00:00, 97.40 batches/s, loss=[]]                   \n",
      "Epoch 181/200: : 5 batches [00:00, 89.34 batches/s, loss=[]]                   \n",
      "Epoch 182/200: : 5 batches [00:00, 98.31 batches/s, loss=[]]                   \n",
      "Epoch 183/200: : 5 batches [00:00, 77.44 batches/s, loss=[]]                   \n",
      "Epoch 184/200: : 5 batches [00:00, 103.88 batches/s, loss=[]]                  \n",
      "Epoch 185/200: : 5 batches [00:00, 115.30 batches/s, loss=[]]                   \n",
      "Epoch 186/200: : 5 batches [00:00, 89.76 batches/s, loss=[]]                    \n",
      "Epoch 187/200: : 5 batches [00:00, 122.02 batches/s, loss=[]]                   \n",
      "Epoch 188/200: : 5 batches [00:00, 174.10 batches/s, loss=[]]                   \n",
      "Epoch 189/200: : 5 batches [00:00, 315.78 batches/s, loss=[]]                   \n",
      "Epoch 190/200: : 5 batches [00:00, 673.76 batches/s, loss=[]]                   \n",
      "Epoch 191/200: : 5 batches [00:00, 172.25 batches/s, loss=[]]                   \n",
      "Epoch 192/200: : 5 batches [00:00, 125.02 batches/s, loss=[]]                   \n",
      "Epoch 193/200: : 5 batches [00:00, 147.58 batches/s, loss=[]]                   \n",
      "Epoch 194/200: : 5 batches [00:00, 136.50 batches/s, loss=[]]                   \n",
      "Epoch 195/200: : 5 batches [00:00, 75.28 batches/s, loss=[]]                   \n",
      "Epoch 196/200: : 5 batches [00:00, 217.99 batches/s, loss=[]]                   \n",
      "Epoch 197/200: : 5 batches [00:00, 136.25 batches/s, loss=[]]                   \n",
      "Epoch 198/200: : 5 batches [00:00, 70.56 batches/s, loss=[]]                   \n",
      "Epoch 199/200: : 5 batches [00:00, 215.69 batches/s, loss=[]]                   \n",
      "Epoch 200/200: : 5 batches [00:00, 153.96 batches/s, loss=[]]                   \n"
     ]
    }
   ],
   "source": [
    "# Define your model EXACTLY as normal\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = Network()\n",
    "trainer = ModuleTrainer(model)\n",
    "\n",
    "trainer.compile(loss='nll_loss',\n",
    "                optimizer='adam')\n",
    "\n",
    "trainer.fit(X, y, \n",
    "            num_epoch=200, \n",
    "            batch_size=32,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.29505884647369385}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0322 -3.4524\n",
       "-0.6931 -0.6931\n",
       "-0.0119 -4.4341\n",
       "-0.0451 -3.1209\n",
       "-0.6931 -0.6931\n",
       "-0.0060 -5.1203\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0088 -4.7421\n",
       "-0.0386 -3.2741\n",
       "-0.0464 -3.0932\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.5870 -0.8119\n",
       "-0.0095 -4.6561\n",
       "-0.1201 -2.1788\n",
       "-0.1138 -2.2294\n",
       "-0.6931 -0.6931\n",
       "-0.6929 -0.6933\n",
       "-0.0291 -3.5525\n",
       "-0.0250 -3.7009\n",
       "-0.0412 -3.2102\n",
       "-0.0202 -3.9105\n",
       "-0.0755 -2.6210\n",
       "-0.0235 -3.7620\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0373 -3.3082\n",
       "-0.0159 -4.1515\n",
       "-0.0213 -3.8590\n",
       "-0.6931 -0.6931\n",
       "-0.0209 -3.8780\n",
       "-0.6931 -0.6931\n",
       "-0.0276 -3.6019\n",
       "-0.0174 -4.0586\n",
       "-0.6931 -0.6931\n",
       "-0.0187 -3.9869\n",
       "-0.0240 -3.7404\n",
       "-0.2814 -1.4054\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0053 -5.2506\n",
       "-0.6924 -0.6939\n",
       "-0.0333 -3.4186\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0023 -6.0799\n",
       "-0.6931 -0.6931\n",
       "-0.0093 -4.6814\n",
       "-0.6878 -0.6985\n",
       "-0.5784 -0.8228\n",
       "-0.0512 -2.9973\n",
       "-0.6931 -0.6931\n",
       "-0.0198 -3.9303\n",
       "-0.0287 -3.5654\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.1211 -2.1712\n",
       "-0.0461 -3.0996\n",
       "-0.0364 -3.3302\n",
       "-0.6931 -0.6931\n",
       "-0.0721 -2.6659\n",
       "-0.6931 -0.6931\n",
       "-0.6154 -0.7774\n",
       "-0.0043 -5.4531\n",
       "-0.0096 -4.6488\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0269 -3.6290\n",
       "-0.6931 -0.6931\n",
       "-0.0205 -3.8983\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.0212 -3.8638\n",
       "-0.6931 -0.6931\n",
       "-0.6931 -0.6931\n",
       "-0.6795 -0.7070\n",
       "-0.6931 -0.6931\n",
       "-0.0756 -2.6200\n",
       "-0.0467 -3.0872\n",
       "-0.6931 -0.6931\n",
       "-0.0218 -3.8374\n",
       "-0.6931 -0.6931\n",
       "-0.0336 -3.4101\n",
       "-0.0196 -3.9445\n",
       "-0.6931 -0.6931\n",
       "-0.0957 -2.3942\n",
       "-0.0143 -4.2554\n",
       "-0.6931 -0.6931\n",
       "-0.0295 -3.5396\n",
       "-0.6931 -0.6931\n",
       "-0.0416 -3.2009\n",
       "-0.6931 -0.6931\n",
       "[torch.FloatTensor of size 100x2]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(trainer.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
